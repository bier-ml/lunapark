{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas matplotlib seaborn wordcloud missingno scikit-learn xgboost catboost fasttext-wheel nltk optuna -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../dataset.csv\")\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(df.describe())\n",
    "\n",
    "df[\"Оценка (для проекта)\"].value_counts().plot(\n",
    "    kind=\"bar\", title=\"Distribution of Ratings\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"resume_word_count\"] = df[\"Текст резюме Rollup (from Кандидат)\"].apply(\n",
    "    lambda x: len(str(x).split())\n",
    ")\n",
    "df[\"job_desc_word_count\"] = df[\"Текст вакансии от компании (from Вакансия)\"].apply(\n",
    "    lambda x: len(str(x).split())\n",
    ")\n",
    "\n",
    "df[[\"resume_word_count\", \"job_desc_word_count\"]].hist(bins=20, figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_status = [\n",
    "    \"F. Отказали мы\",\n",
    "    \"I.4a. Оценили резюме (не рекомендуем)\",\n",
    "    \"F. Отказал клиент\",\n",
    "    \"I.5a. Передумали питчить\",\n",
    "]\n",
    "good_status = [\n",
    "    \"I.4b. Оценили резюме (рекомендуем)\",\n",
    "    \"I.6. Написали\",\n",
    "    \"II.11. Запомнить\",\n",
    "    \"I.5. Согласуем питч\",\n",
    "    \"II.6. Этап 2\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Статус\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Статус\"].value_counts().sort_values().plot(kind=\"barh\", title=\"Status Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_ratings = df.groupby(\"Статус\")[\"Оценка (для проекта)\"].mean().sort_values()\n",
    "status_ratings.plot(kind=\"barh\", title=\"Average Rating by Status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../dataset.csv\")\n",
    "df = df.dropna(\n",
    "    subset=[\n",
    "        \"Текст вакансии от компании (from Вакансия)\",\n",
    "        \"Текст резюме Rollup (from Кандидат)\",\n",
    "        \"Оценка (для проекта)\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def convert_score(value):\n",
    "    try:\n",
    "        if isinstance(value, (int, float)):\n",
    "            return value\n",
    "\n",
    "        if isinstance(value, str) and \"/\" in value:\n",
    "            num, denom = value.split(\"/\")\n",
    "            return round((float(num) + float(denom)) / 2, 1)\n",
    "\n",
    "        return float(value)\n",
    "\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def custom_metric(y_true, y_pred):\n",
    "    deviation = np.abs(y_true - y_pred)\n",
    "\n",
    "    total_rows = len(y_true)\n",
    "\n",
    "    count_deviation_1_or_more = np.sum(deviation >= 1)\n",
    "    percentage_deviation_1_or_more = count_deviation_1_or_more / total_rows\n",
    "\n",
    "    count_deviation_0_5_or_less = np.sum(deviation <= 0.5)\n",
    "    percentage_deviation_0_5_or_less = count_deviation_0_5_or_less / total_rows\n",
    "\n",
    "    return percentage_deviation_1_or_more, percentage_deviation_0_5_or_less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vacancy = TfidfVectorizer(max_features=500)\n",
    "tfidf_resume = TfidfVectorizer(max_features=500)\n",
    "\n",
    "vacancy_tfidf = tfidf_vacancy.fit_transform(\n",
    "    df[\"Текст вакансии от компании (from Вакансия)\"]\n",
    ")\n",
    "resume_tfidf = tfidf_resume.fit_transform(df[\"Текст резюме Rollup (from Кандидат)\"])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X = np.hstack((vacancy_tfidf.toarray(), resume_tfidf.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df[\"Оценка (для проекта)\"].apply(convert_score)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "X = df[\n",
    "    [\n",
    "        \"Текст вакансии от компании (from Вакансия)\",\n",
    "        \"Текст резюме Rollup (from Кандидат)\",\n",
    "    ]\n",
    "]\n",
    "y = df[\"Оценка (для проекта)\"].apply(convert_score)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "def custom_metric(y_true, y_pred):\n",
    "    deviation = np.abs(y_true - y_pred)\n",
    "    total_rows = len(y_true)\n",
    "\n",
    "    count_deviation_1_or_more = np.sum(deviation >= 1)\n",
    "    percentage_deviation_1_or_more = count_deviation_1_or_more / total_rows\n",
    "\n",
    "    count_deviation_0_5_to_1 = np.sum((deviation > 0.5) & (deviation < 1.0))\n",
    "    percentage_deviation_0_5_to_1 = count_deviation_0_5_to_1 / total_rows\n",
    "\n",
    "    return percentage_deviation_1_or_more, percentage_deviation_0_5_to_1\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    iterations = trial.suggest_int(\"iterations\", 500, 1500)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.1)\n",
    "    depth = trial.suggest_int(\"depth\", 4, 10)\n",
    "    l2_leaf_reg = trial.suggest_int(\"l2_leaf_reg\", 1, 10)\n",
    "    bagging_temperature = trial.suggest_float(\"bagging_temperature\", 0, 3)\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=iterations,\n",
    "        learning_rate=learning_rate,\n",
    "        depth=depth,\n",
    "        l2_leaf_reg=l2_leaf_reg,\n",
    "        bagging_temperature=bagging_temperature,\n",
    "        eval_metric=\"RMSE\",\n",
    "        text_features=[\n",
    "            \"Текст вакансии от компании (from Вакансия)\",\n",
    "            \"Текст резюме Rollup (from Кандидат)\",\n",
    "        ],\n",
    "        verbose=0,\n",
    "        early_stopping_rounds=100,\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    percentage_deviation_1_or_more, percentage_deviation_0_5_to_1 = custom_metric(\n",
    "        y_test, y_pred\n",
    "    )\n",
    "\n",
    "    target_deviation_1_or_more = 0.05\n",
    "    target_deviation_0_5_to_1 = 0.2\n",
    "\n",
    "    penalty_1_or_more = percentage_deviation_1_or_more - target_deviation_1_or_more\n",
    "    penalty_0_5_to_1 = percentage_deviation_0_5_to_1 - target_deviation_0_5_to_1\n",
    "\n",
    "    combined_penalty = penalty_1_or_more + penalty_0_5_to_1\n",
    "\n",
    "    return combined_penalty\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best trial: {best_trial.number} with value: {best_trial.value}\")\n",
    "print(\"Best parameters:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"iterations\": 848,\n",
    "    \"learning_rate\": 0.02461841312190255,\n",
    "    \"depth\": 5,\n",
    "    \"l2_leaf_reg\": 9,\n",
    "    \"bagging_temperature\": 2.6931515237347994,\n",
    "    \"eval_metric\": \"RMSE\",\n",
    "    \"loss_function\": \"RMSE\",\n",
    "    \"text_features\": [\n",
    "        \"Текст вакансии от компании (from Вакансия)\",\n",
    "        \"Текст резюме Rollup (from Кандидат)\",\n",
    "    ],\n",
    "    \"verbose\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_5, metric_20 = custom_metric(y_test, y_pred)\n",
    "print(\n",
    "    f\"Custom Metric - deviation of 1 or more: {metric_5}, deviation of 0.5 or less: {metric_20}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Catboost with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "X = df[\n",
    "    [\n",
    "        \"Текст вакансии от компании (from Вакансия)\",\n",
    "        \"Текст резюме Rollup (from Кандидат)\",\n",
    "    ]\n",
    "]\n",
    "y = df[\"Оценка (для проекта)\"].apply(convert_score)\n",
    "\n",
    "\n",
    "def custom_cv(X, y, model_params, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    penalties_1_or_more = []\n",
    "    penalties_05_to_1 = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        train_pool = Pool(\n",
    "            X_train_fold,\n",
    "            y_train_fold,\n",
    "            text_features=[\n",
    "                \"Текст вакансии от компании (from Вакансия)\",\n",
    "                \"Текст резюме Rollup (from Кандидат)\",\n",
    "            ],\n",
    "        )\n",
    "        test_pool = Pool(\n",
    "            X_test_fold,\n",
    "            y_test_fold,\n",
    "            text_features=[\n",
    "                \"Текст вакансии от компании (from Вакансия)\",\n",
    "                \"Текст резюме Rollup (from Кандидат)\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        model = CatBoostRegressor(**model_params)\n",
    "        model.fit(train_pool, eval_set=test_pool)\n",
    "\n",
    "        y_pred = model.predict(test_pool)\n",
    "\n",
    "        percentage_deviation_1_or_more, percentage_deviation_0_5_to_1 = custom_metric(\n",
    "            y_test_fold, y_pred\n",
    "        )\n",
    "\n",
    "        penalties_1_or_more.append(percentage_deviation_1_or_more)\n",
    "        penalties_05_to_1.append(percentage_deviation_0_5_to_1)\n",
    "\n",
    "    return penalties_1_or_more, penalties_05_to_1\n",
    "\n",
    "\n",
    "model_params = {\n",
    "    \"iterations\": 848,\n",
    "    \"learning_rate\": 0.02461841312190255,\n",
    "    \"depth\": 5,\n",
    "    \"l2_leaf_reg\": 9,\n",
    "    \"bagging_temperature\": 2.6931515237347994,\n",
    "    \"early_stopping_rounds\": 100,\n",
    "    \"verbose\": 0,\n",
    "}\n",
    "\n",
    "average_penalty = custom_cv(X, y, model_params, n_splits=5)\n",
    "\n",
    "mean_penalty_1_or_more = np.mean(average_penalty[0])\n",
    "std_penalty_1_or_more = np.std(average_penalty[0])\n",
    "\n",
    "mean_penalty_0_5_to_1 = np.mean(average_penalty[1])\n",
    "std_penalty_0_5_to_1 = np.std(average_penalty[1])\n",
    "\n",
    "print(\n",
    "    f\"Mean deviation >= 1: {mean_penalty_1_or_more:.4f}, Std: {std_penalty_1_or_more:.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Mean deviation between 0.5 and 1: {mean_penalty_0_5_to_1:.4f}, Std: {std_penalty_0_5_to_1:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "\n",
    "def custom_metric(y_true, y_pred):\n",
    "    deviation = np.abs(y_true - y_pred)\n",
    "    total_rows = len(y_true)\n",
    "\n",
    "    count_deviation_1_or_more = np.sum(deviation >= 1)\n",
    "    percentage_deviation_1_or_more = (count_deviation_1_or_more / total_rows) * 100\n",
    "\n",
    "    count_deviation_0_5_to_1 = np.sum((deviation > 0.5) & (deviation < 1.0))\n",
    "    percentage_deviation_0_5_to_1 = (count_deviation_0_5_to_1 / total_rows) * 100\n",
    "\n",
    "    return percentage_deviation_1_or_more, percentage_deviation_0_5_to_1\n",
    "\n",
    "\n",
    "best_params = {\n",
    "    \"iterations\": 848,\n",
    "    \"learning_rate\": 0.02461841312190255,\n",
    "    \"depth\": 5,\n",
    "    \"l2_leaf_reg\": 9,\n",
    "    \"bagging_temperature\": 2.6931515237347994,\n",
    "    \"loss_function\": \"RMSE\",\n",
    "    \"eval_metric\": \"RMSE\",\n",
    "    \"text_features\": [\n",
    "        \"Текст вакансии от компании (from Вакансия)\",\n",
    "        \"Текст резюме Rollup (from Кандидат)\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "custom_penalties = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "\n",
    "    train_pool = Pool(\n",
    "        data=X_train_fold,\n",
    "        label=y_train_fold,\n",
    "        text_features=best_params[\"text_features\"],\n",
    "    )\n",
    "\n",
    "    model = CatBoostRegressor(**best_params)\n",
    "    model.fit(train_pool, eval_set=(X_test_fold, y_test_fold), verbose=0)\n",
    "\n",
    "    y_pred = model.predict(X_test_fold)\n",
    "\n",
    "    percentage_deviation_1_or_more, percentage_deviation_0_5_to_1 = custom_metric(\n",
    "        y_test_fold, y_pred\n",
    "    )\n",
    "\n",
    "    target_deviation_1_or_more = 0.05\n",
    "    target_deviation_0_5_to_1 = 0.2\n",
    "\n",
    "    penalty_1_or_more = percentage_deviation_1_or_more - target_deviation_1_or_more\n",
    "    penalty_0_5_to_1 = percentage_deviation_0_5_to_1 - target_deviation_0_5_to_1\n",
    "\n",
    "    combined_penalty = penalty_1_or_more + penalty_0_5_to_1\n",
    "    custom_penalties.append(combined_penalty)\n",
    "\n",
    "print(\"Custom penalties for each fold:\", custom_penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(y_true, y_pred):\n",
    "    deviation = np.abs(y_true - y_pred)\n",
    "    total_rows = len(y_true)\n",
    "\n",
    "    count_deviation_1_or_more = np.sum(deviation >= 1)\n",
    "    percentage_deviation_1_or_more = (count_deviation_1_or_more / total_rows) * 100\n",
    "\n",
    "    count_deviation_0_5_to_1 = np.sum((deviation > 0.5) & (deviation < 1.0))\n",
    "    percentage_deviation_0_5_to_1 = (count_deviation_0_5_to_1 / total_rows) * 100\n",
    "\n",
    "    return percentage_deviation_1_or_more, percentage_deviation_0_5_to_1\n",
    "\n",
    "\n",
    "metric_5, metric_20 = custom_metric(y_test, y_pred)\n",
    "print(\n",
    "    f\"Custom Metric - deviation of 1 or more: {metric_5}, deviation of 0.5 or less: {metric_20}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost with custom objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDeviationObjective:\n",
    "    def calc_ders_range(self, approxes, targets, weights):\n",
    "        assert len(approxes) == len(targets)\n",
    "        if weights is not None:\n",
    "            assert len(weights) == len(approxes)\n",
    "\n",
    "        result = []\n",
    "        for index in range(len(targets)):\n",
    "            der1 = targets[index] - approxes[index]\n",
    "            der2 = -1\n",
    "\n",
    "            if abs(der1) >= 1:\n",
    "                der1 *= 10\n",
    "            elif abs(der1) >= 0.5:\n",
    "                der1 *= 2\n",
    "\n",
    "            if weights is not None:\n",
    "                der1 *= weights[index]\n",
    "                der2 *= weights[index]\n",
    "\n",
    "            result.append((der1, der2))\n",
    "        return result\n",
    "\n",
    "\n",
    "class CustomDeviationMetric:\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "\n",
    "        approx = approxes[0]\n",
    "        error_sum = 0.0\n",
    "        weight_sum = 0.0\n",
    "\n",
    "        for i in range(len(approx)):\n",
    "            w = 1.0 if weight is None else weight[i]\n",
    "            weight_sum += w\n",
    "\n",
    "            abs_deviation = np.abs(approx[i] - target[i])\n",
    "            if abs_deviation >= 1:\n",
    "                error_sum += w * 10\n",
    "            elif abs_deviation >= 0.5:\n",
    "                error_sum += w * 2\n",
    "            else:\n",
    "                error_sum += w * 1\n",
    "\n",
    "        return error_sum, weight_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import fasttext\n",
    "\n",
    "\n",
    "model = fasttext.load_model(\"./cc.ru.300.bin/cc.ru.300.bin\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "def get_fasttext_vectors(texts):\n",
    "    return np.array([model.get_word_vector(text) for text in texts])\n",
    "\n",
    "\n",
    "X_train_vacancy_fasttext = get_fasttext_vectors(\n",
    "    X_train[\"Текст вакансии от компании (from Вакансия)\"].values\n",
    ")\n",
    "X_train_resume_fasttext = get_fasttext_vectors(\n",
    "    X_train[\"Текст резюме Rollup (from Кандидат)\"].values\n",
    ")\n",
    "\n",
    "X_test_vacancy_fasttext = get_fasttext_vectors(\n",
    "    X_test[\"Текст вакансии от компании (from Вакансия)\"].values\n",
    ")\n",
    "X_test_resume_fasttext = get_fasttext_vectors(\n",
    "    X_test[\"Текст резюме Rollup (from Кандидат)\"].values\n",
    ")\n",
    "\n",
    "X_train_combined = np.hstack((X_train_vacancy_fasttext, X_train_resume_fasttext))\n",
    "X_test_combined = np.hstack((X_test_vacancy_fasttext, X_test_resume_fasttext))\n",
    "\n",
    "model = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function=CustomDeviationObjective(),\n",
    "    eval_metric=CustomDeviationMetric(),\n",
    "    verbose=100,\n",
    ")\n",
    "\n",
    "model.fit(X_train_combined, y_train, eval_set=(X_test_combined, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test_combined)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"CatBoost with Russian FastText - Mean Squared Error: {mse}, R-squared: {r2}\")\n",
    "\n",
    "\n",
    "def custom_metric(y_true, y_pred):\n",
    "    deviation_1 = ((y_true - y_pred).abs() >= 1).sum() / len(y_true)\n",
    "    deviation_05 = ((y_true - y_pred).abs() >= 0.5).sum() / len(y_true)\n",
    "\n",
    "    return deviation_1, deviation_05\n",
    "\n",
    "\n",
    "metric_5, metric_20 = custom_metric(y_test, y_pred)\n",
    "print(\n",
    "    f\"Custom Metric - deviation of 1 or more: {metric_5}, deviation of 0.5 or less: {metric_20}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost with Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import fasttext\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = fasttext.load_model(\"./cc.ru.300.bin/cc.ru.300.bin\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "def get_fasttext_vectors(texts):\n",
    "    return np.array([model.get_word_vector(text) for text in texts])\n",
    "\n",
    "\n",
    "X_train_vacancy_fasttext = get_fasttext_vectors(\n",
    "    X_train[\"Текст вакансии от компании (from Вакансия)\"].values\n",
    ")\n",
    "X_train_resume_fasttext = get_fasttext_vectors(\n",
    "    X_train[\"Текст резюме Rollup (from Кандидат)\"].values\n",
    ")\n",
    "\n",
    "X_test_vacancy_fasttext = get_fasttext_vectors(\n",
    "    X_test[\"Текст вакансии от компании (from Вакансия)\"].values\n",
    ")\n",
    "X_test_resume_fasttext = get_fasttext_vectors(\n",
    "    X_test[\"Текст резюме Rollup (from Кандидат)\"].values\n",
    ")\n",
    "\n",
    "X_train_combined = np.hstack((X_train_vacancy_fasttext, X_train_resume_fasttext))\n",
    "X_test_combined = np.hstack((X_test_vacancy_fasttext, X_test_resume_fasttext))\n",
    "\n",
    "model_catboost = CatBoostRegressor(\n",
    "    iterations=1000, learning_rate=0.1, depth=6, eval_metric=\"RMSE\", verbose=100\n",
    ")\n",
    "\n",
    "model_catboost.fit(X_train_combined, y_train, eval_set=(X_test_combined, y_test))\n",
    "\n",
    "y_pred = model_catboost.predict(X_test_combined)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"CatBoost with Russian FastText - Mean Squared Error: {mse}, R-squared: {r2}\")\n",
    "\n",
    "\n",
    "def custom_metric(y_true, y_pred):\n",
    "    deviation_1 = ((y_true - y_pred).abs() >= 1).sum() / len(y_true)\n",
    "    deviation_05 = ((y_true - y_pred).abs() >= 0.5).sum() / len(y_true)\n",
    "\n",
    "    return deviation_1, deviation_05\n",
    "\n",
    "\n",
    "metric_5, metric_20 = custom_metric(y_test, y_pred)\n",
    "print(\n",
    "    f\"Custom Metric - deviation of 1 or more: {metric_5}, deviation of 0.5 or less: {metric_20}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = fasttext.load_model(\"./cc.ru.300.bin/cc.ru.300.bin\")\n",
    "\n",
    "X = df[\n",
    "    [\n",
    "        \"Текст вакансии от компании (from Вакансия)\",\n",
    "        \"Текст резюме Rollup (from Кандидат)\",\n",
    "    ]\n",
    "]\n",
    "y = df[\"Оценка (для проекта)\"].apply(convert_score)  # Assuming convert_score is defined\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "def get_fasttext_vectors(texts):\n",
    "    return np.array([model.get_word_vector(text) for text in texts])\n",
    "\n",
    "\n",
    "X_train_vacancy_fasttext = get_fasttext_vectors(\n",
    "    X_train[\"Текст вакансии от компании (from Вакансия)\"].values\n",
    ")\n",
    "X_train_resume_fasttext = get_fasttext_vectors(\n",
    "    X_train[\"Текст резюме Rollup (from Кандидат)\"].values\n",
    ")\n",
    "\n",
    "X_test_vacancy_fasttext = get_fasttext_vectors(\n",
    "    X_test[\"Текст вакансии от компании (from Вакансия)\"].values\n",
    ")\n",
    "X_test_resume_fasttext = get_fasttext_vectors(\n",
    "    X_test[\"Текст резюме Rollup (from Кандидат)\"].values\n",
    ")\n",
    "\n",
    "X_train_combined = np.hstack((X_train_vacancy_fasttext, X_train_resume_fasttext))\n",
    "X_test_combined = np.hstack((X_test_vacancy_fasttext, X_test_resume_fasttext))\n",
    "\n",
    "model_xgboost = XGBRegressor(\n",
    "    n_estimators=1000, learning_rate=0.1, max_depth=6, eval_metric=\"rmse\", verbosity=1\n",
    ")\n",
    "\n",
    "model_xgboost.fit(X_train_combined, y_train)\n",
    "\n",
    "y_pred = model_xgboost.predict(X_test_combined)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"XGBoost with Russian FastText - Mean Squared Error: {mse}, R-squared: {r2}\")\n",
    "\n",
    "\n",
    "def custom_metric(y_true, y_pred):\n",
    "    deviation_1 = ((y_true - y_pred).abs() >= 1).sum() / len(y_true)\n",
    "    deviation_05 = ((y_true - y_pred).abs() >= 0.5).sum() / len(y_true)\n",
    "\n",
    "    return deviation_1, deviation_05\n",
    "\n",
    "\n",
    "metric_5, metric_20 = custom_metric(y_test, y_pred)\n",
    "print(\n",
    "    f\"Custom Metric - deviation of 1 or more: {metric_5}, deviation of 0.5 or less: {metric_20}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    StackingRegressor,\n",
    "    GradientBoostingRegressor,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "model = fasttext.load_model(\"./cc.ru.300.bin/cc.ru.300.bin\")\n",
    "\n",
    "X = df[\n",
    "    [\n",
    "        \"Текст вакансии от компании (from Вакансия)\",\n",
    "        \"Текст резюме Rollup (from Кандидат)\",\n",
    "    ]\n",
    "]\n",
    "y = df[\"Оценка (для проекта)\"].apply(convert_score)  # Assuming convert_score is defined\n",
    "\n",
    "X[\"Текст вакансии от компании (from Вакансия)\"] = X[\n",
    "    \"Текст вакансии от компании (from Вакансия)\"\n",
    "].apply(preprocess_text)\n",
    "X[\"Текст резюме Rollup (from Кандидат)\"] = X[\n",
    "    \"Текст резюме Rollup (from Кандидат)\"\n",
    "].apply(preprocess_text)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "def get_fasttext_vectors(texts):\n",
    "    return np.array([model.get_word_vector(text) for text in texts])\n",
    "\n",
    "\n",
    "X_train_vacancy_fasttext = get_fasttext_vectors(\n",
    "    X_train[\"Текст вакансии от компании (from Вакансия)\"].values\n",
    ")\n",
    "X_train_resume_fasttext = get_fasttext_vectors(\n",
    "    X_train[\"Текст резюме Rollup (from Кандидат)\"].values\n",
    ")\n",
    "\n",
    "X_test_vacancy_fasttext = get_fasttext_vectors(\n",
    "    X_test[\"Текст вакансии от компании (from Вакансия)\"].values\n",
    ")\n",
    "X_test_resume_fasttext = get_fasttext_vectors(\n",
    "    X_test[\"Текст резюме Rollup (from Кандидат)\"].values\n",
    ")\n",
    "\n",
    "X_train_combined = np.hstack((X_train_vacancy_fasttext, X_train_resume_fasttext))\n",
    "X_test_combined = np.hstack((X_test_vacancy_fasttext, X_test_resume_fasttext))\n",
    "\n",
    "base_models = [\n",
    "    (\"rf\", RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    (\n",
    "        \"xgb\",\n",
    "        XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42),\n",
    "    ),\n",
    "    (\n",
    "        \"catboost\",\n",
    "        CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, verbose=0),\n",
    "    ),\n",
    "]\n",
    "\n",
    "stacked_model = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=GradientBoostingRegressor(\n",
    "        n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42\n",
    "    ),\n",
    ")\n",
    "\n",
    "stacked_model.fit(X_train_combined, y_train)\n",
    "\n",
    "y_pred_stacked = stacked_model.predict(X_test_combined)\n",
    "\n",
    "mse_final = mean_squared_error(y_test, y_pred_stacked)\n",
    "r2_final = r2_score(y_test, y_pred_stacked)\n",
    "print(f\"Stacked Model - Mean Squared Error: {mse_final}, R-squared: {r2_final}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
