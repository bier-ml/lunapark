{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas matplotlib seaborn wordcloud missingno scikit-learn xgboost catboost fasttext-wheel nltk optuna -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../dataset.csv')\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(df.describe())\n",
    "\n",
    "df['Оценка (для проекта)'].value_counts().plot(kind='bar', title='Distribution of Ratings')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['resume_word_count'] = df['Текст резюме Rollup (from Кандидат)'].apply(lambda x: len(str(x).split()))\n",
    "df['job_desc_word_count'] = df['Текст вакансии от компании (from Вакансия)'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "df[['resume_word_count', 'job_desc_word_count']].hist(bins=20, figsize=(10, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_status=[\"F. Отказали мы\", \"I.4a. Оценили резюме (не рекомендуем)\", \"F. Отказал клиент\", \"I.5a. Передумали питчить\"]\n",
    "good_status=[\"I.4b. Оценили резюме (рекомендуем)\", \"I.6. Написали\", \"II.11. Запомнить\", \"I.5. Согласуем питч\", \"II.6. Этап 2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Статус'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Статус'].value_counts().sort_values().plot(kind='barh', title='Status Distribution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_ratings = df.groupby('Статус')['Оценка (для проекта)'].mean().sort_values()\n",
    "status_ratings.plot(kind='barh', title='Average Rating by Status')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../dataset.csv')\n",
    "df = df.dropna(subset=['Текст вакансии от компании (from Вакансия)', 'Текст резюме Rollup (from Кандидат)', 'Оценка (для проекта)'])\n",
    "\n",
    "def convert_score(value):\n",
    "    try:\n",
    "        if isinstance(value, (int, float)):\n",
    "            return value\n",
    "        \n",
    "        if isinstance(value, str) and '/' in value:\n",
    "            num, denom = value.split('/')\n",
    "            return round((float(num) + float(denom))/2, 1)\n",
    "        \n",
    "        return float(value)\n",
    "    \n",
    "    except ValueError:\n",
    "        return None \n",
    "\n",
    "def custom_metric(y_true, y_pred):\n",
    "    deviation = np.abs(y_true - y_pred)\n",
    "\n",
    "    total_rows = len(y_true)\n",
    "\n",
    "    count_deviation_1_or_more = np.sum(deviation >= 1)\n",
    "    percentage_deviation_1_or_more = (count_deviation_1_or_more / total_rows)\n",
    "\n",
    "    count_deviation_0_5_or_less = np.sum(deviation <= 0.5)\n",
    "    percentage_deviation_0_5_or_less = (count_deviation_0_5_or_less / total_rows)\n",
    "\n",
    "    return percentage_deviation_1_or_more, percentage_deviation_0_5_or_less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vacancy = TfidfVectorizer(max_features=500)\n",
    "tfidf_resume = TfidfVectorizer(max_features=500)\n",
    "\n",
    "vacancy_tfidf = tfidf_vacancy.fit_transform(df['Текст вакансии от компании (from Вакансия)'])\n",
    "resume_tfidf = tfidf_resume.fit_transform(df['Текст резюме Rollup (from Кандидат)'])\n",
    "\n",
    "import numpy as np\n",
    "X = np.hstack((vacancy_tfidf.toarray(), resume_tfidf.toarray()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['Оценка (для проекта)'].apply(convert_score)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R-squared: {r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "X = df[['Текст вакансии от компании (from Вакансия)', 'Текст резюме Rollup (from Кандидат)']]\n",
    "y = df['Оценка (для проекта)'].apply(convert_score)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def custom_metric(y_true, y_pred):\n",
    "    deviation = np.abs(y_true - y_pred)\n",
    "    total_rows = len(y_true)\n",
    "\n",
    "    count_deviation_1_or_more = np.sum(deviation >= 1)\n",
    "    percentage_deviation_1_or_more = (count_deviation_1_or_more / total_rows)\n",
    "\n",
    "    count_deviation_0_5_to_1 = np.sum((deviation > 0.5) & (deviation < 1.0))\n",
    "    percentage_deviation_0_5_to_1 = (count_deviation_0_5_to_1 / total_rows)\n",
    "\n",
    "    return percentage_deviation_1_or_more, percentage_deviation_0_5_to_1\n",
    "\n",
    "def objective(trial):\n",
    "    iterations = trial.suggest_int('iterations', 500, 1500)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.1)\n",
    "    depth = trial.suggest_int('depth', 4, 10)\n",
    "    l2_leaf_reg = trial.suggest_int('l2_leaf_reg', 1, 10)\n",
    "    bagging_temperature = trial.suggest_float('bagging_temperature', 0, 3)\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=iterations,\n",
    "        learning_rate=learning_rate,\n",
    "        depth=depth,\n",
    "        l2_leaf_reg=l2_leaf_reg,\n",
    "        bagging_temperature=bagging_temperature,\n",
    "        eval_metric='RMSE',\n",
    "        text_features=['Текст вакансии от компании (from Вакансия)', 'Текст резюме Rollup (from Кандидат)'],\n",
    "        verbose=0,\n",
    "        early_stopping_rounds=100\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    percentage_deviation_1_or_more, percentage_deviation_0_5_to_1 = custom_metric(y_test, y_pred)\n",
    "\n",
    "    target_deviation_1_or_more = 0.05\n",
    "    target_deviation_0_5_to_1 = 0.2\n",
    "\n",
    "    penalty_1_or_more = percentage_deviation_1_or_more - target_deviation_1_or_more\n",
    "    penalty_0_5_to_1 = percentage_deviation_0_5_to_1 - target_deviation_0_5_to_1\n",
    "\n",
    "    combined_penalty = penalty_1_or_more + penalty_0_5_to_1\n",
    "\n",
    "    return combined_penalty\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best trial: {best_trial.number} with value: {best_trial.value}\")\n",
    "print(\"Best parameters:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'iterations': 848,\n",
    "    'learning_rate': 0.02461841312190255,\n",
    "    'depth': 5,\n",
    "    'l2_leaf_reg': 9,\n",
    "    'bagging_temperature': 2.6931515237347994,\n",
    "    'eval_metric': 'RMSE',\n",
    "    'loss_function': 'RMSE',\n",
    "    'text_features': ['Текст вакансии от компании (from Вакансия)', 'Текст резюме Rollup (from Кандидат)'],\n",
    "    'verbose': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_5, metric_20 = custom_metric(y_test, y_pred)\n",
    "print(f'Custom Metric - deviation of 1 or more: {metric_5}, deviation of 0.5 or less: {metric_20}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Catboost with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "X = df[['Текст вакансии от компании (from Вакансия)', 'Текст резюме Rollup (from Кандидат)']]\n",
    "y = df['Оценка (для проекта)'].apply(convert_score)  \n",
    "\n",
    "def custom_cv(X, y, model_params, n_splits=5):  \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    penalties_1_or_more = []\n",
    "    penalties_05_to_1 = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        train_pool = Pool(X_train_fold, y_train_fold, text_features=['Текст вакансии от компании (from Вакансия)', 'Текст резюме Rollup (from Кандидат)'])\n",
    "        test_pool = Pool(X_test_fold, y_test_fold, text_features=['Текст вакансии от компании (from Вакансия)', 'Текст резюме Rollup (from Кандидат)'])\n",
    "\n",
    "        model = CatBoostRegressor(**model_params)\n",
    "        model.fit(train_pool, eval_set=test_pool)\n",
    "\n",
    "        y_pred = model.predict(test_pool)\n",
    "\n",
    "        percentage_deviation_1_or_more, percentage_deviation_0_5_to_1 = custom_metric(y_test_fold, y_pred)\n",
    "\n",
    "        penalties_1_or_more.append(percentage_deviation_1_or_more)\n",
    "        penalties_05_to_1.append(percentage_deviation_0_5_to_1)\n",
    "\n",
    "    return penalties_1_or_more, penalties_05_to_1\n",
    "\n",
    "model_params = {\n",
    "    'iterations': 848,\n",
    "    'learning_rate': 0.02461841312190255,\n",
    "    'depth': 5,\n",
    "    'l2_leaf_reg': 9,\n",
    "    'bagging_temperature': 2.6931515237347994,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "average_penalty = custom_cv(X, y, model_params, n_splits=5)\n",
    "\n",
    "mean_penalty_1_or_more = np.mean(average_penalty[0])\n",
    "std_penalty_1_or_more = np.std(average_penalty[0])\n",
    "\n",
    "mean_penalty_0_5_to_1 = np.mean(average_penalty[1])\n",
    "std_penalty_0_5_to_1 = np.std(average_penalty[1])\n",
    "\n",
    "print(f\"Mean deviation >= 1: {mean_penalty_1_or_more:.4f}, Std: {std_penalty_1_or_more:.4f}\")\n",
    "print(f\"Mean deviation between 0.5 and 1: {mean_penalty_0_5_to_1:.4f}, Std: {std_penalty_0_5_to_1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "def custom_metric(y_true, y_pred):\n",
    "    deviation = np.abs(y_true - y_pred)\n",
    "    total_rows = len(y_true)\n",
    "\n",
    "    count_deviation_1_or_more = np.sum(deviation >= 1)\n",
    "    percentage_deviation_1_or_more = (count_deviation_1_or_more / total_rows) * 100\n",
    "\n",
    "    count_deviation_0_5_to_1 = np.sum((deviation > 0.5) & (deviation < 1.0))\n",
    "    percentage_deviation_0_5_to_1 = (count_deviation_0_5_to_1 / total_rows) * 100\n",
    "\n",
    "    return percentage_deviation_1_or_more, percentage_deviation_0_5_to_1\n",
    "\n",
    "best_params = {\n",
    "    'iterations': 848,\n",
    "    'learning_rate': 0.02461841312190255,\n",
    "    'depth': 5,\n",
    "    'l2_leaf_reg': 9,\n",
    "    'bagging_temperature': 2.6931515237347994,\n",
    "    'loss_function': 'RMSE',\n",
    "    'eval_metric': 'RMSE',\n",
    "    'text_features': ['Текст вакансии от компании (from Вакансия)', 'Текст резюме Rollup (from Кандидат)']\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "custom_penalties = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "    \n",
    "    train_pool = Pool(data=X_train_fold, label=y_train_fold, text_features=best_params['text_features'])\n",
    "    \n",
    "    model = CatBoostRegressor(**best_params)\n",
    "    model.fit(train_pool, eval_set=(X_test_fold, y_test_fold), verbose=0)\n",
    "\n",
    "    y_pred = model.predict(X_test_fold)\n",
    "\n",
    "    percentage_deviation_1_or_more, percentage_deviation_0_5_to_1 = custom_metric(y_test_fold, y_pred)\n",
    "\n",
    "    target_deviation_1_or_more = 0.05\n",
    "    target_deviation_0_5_to_1 = 0.2\n",
    "\n",
    "    penalty_1_or_more = percentage_deviation_1_or_more - target_deviation_1_or_more\n",
    "    penalty_0_5_to_1 = percentage_deviation_0_5_to_1 - target_deviation_0_5_to_1\n",
    "\n",
    "    combined_penalty = penalty_1_or_more + penalty_0_5_to_1\n",
    "    custom_penalties.append(combined_penalty)\n",
    "\n",
    "print(\"Custom penalties for each fold:\", custom_penalties)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(y_true, y_pred):\n",
    "    deviation = np.abs(y_true - y_pred)\n",
    "    total_rows = len(y_true)\n",
    "\n",
    "    count_deviation_1_or_more = np.sum(deviation >= 1)\n",
    "    percentage_deviation_1_or_more = (count_deviation_1_or_more / total_rows) * 100\n",
    "\n",
    "    count_deviation_0_5_to_1 = np.sum((deviation > 0.5) & (deviation < 1.0))\n",
    "    percentage_deviation_0_5_to_1 = (count_deviation_0_5_to_1 / total_rows) * 100\n",
    "\n",
    "    return percentage_deviation_1_or_more, percentage_deviation_0_5_to_1\n",
    "metric_5, metric_20 = custom_metric(y_test, y_pred)\n",
    "print(f'Custom Metric - deviation of 1 or more: {metric_5}, deviation of 0.5 or less: {metric_20}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost with custom objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDeviationObjective:\n",
    "    def calc_ders_range(self, approxes, targets, weights):\n",
    "        assert len(approxes) == len(targets)\n",
    "        if weights is not None:\n",
    "            assert len(weights) == len(approxes)\n",
    "\n",
    "        result = []\n",
    "        for index in range(len(targets)):\n",
    "            der1 = targets[index] - approxes[index]\n",
    "            der2 = -1\n",
    "\n",
    "            if abs(der1) >= 1:\n",
    "                der1 *= 10 \n",
    "            elif abs(der1) >= 0.5:\n",
    "                der1 *= 2 \n",
    "\n",
    "            if weights is not None:\n",
    "                der1 *= weights[index]\n",
    "                der2 *= weights[index]\n",
    "\n",
    "            result.append((der1, der2))\n",
    "        return result\n",
    "\n",
    "class CustomDeviationMetric:\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error \n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "\n",
    "        approx = approxes[0]\n",
    "        error_sum = 0.0\n",
    "        weight_sum = 0.0\n",
    "\n",
    "        for i in range(len(approx)):\n",
    "            w = 1.0 if weight is None else weight[i]\n",
    "            weight_sum += w\n",
    "            \n",
    "            abs_deviation = np.abs(approx[i] - target[i])\n",
    "            if abs_deviation >= 1:\n",
    "                error_sum += w * 10 \n",
    "            elif abs_deviation >= 0.5:\n",
    "                error_sum += w * 2\n",
    "            else:\n",
    "                error_sum += w * 1 \n",
    "\n",
    "        return error_sum, weight_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import fasttext\n",
    "\n",
    "\n",
    "model = fasttext.load_model('./cc.ru.300.bin/cc.ru.300.bin')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def get_fasttext_vectors(texts):\n",
    "    return np.array([model.get_word_vector(text) for text in texts])\n",
    "\n",
    "X_train_vacancy_fasttext = get_fasttext_vectors(X_train['Текст вакансии от компании (from Вакансия)'].values)\n",
    "X_train_resume_fasttext = get_fasttext_vectors(X_train['Текст резюме Rollup (from Кандидат)'].values)\n",
    "\n",
    "X_test_vacancy_fasttext = get_fasttext_vectors(X_test['Текст вакансии от компании (from Вакансия)'].values)\n",
    "X_test_resume_fasttext = get_fasttext_vectors(X_test['Текст резюме Rollup (from Кандидат)'].values)\n",
    "\n",
    "X_train_combined = np.hstack((X_train_vacancy_fasttext, X_train_resume_fasttext))\n",
    "X_test_combined = np.hstack((X_test_vacancy_fasttext, X_test_resume_fasttext))\n",
    "\n",
    "model = CatBoostRegressor(iterations=1000,\n",
    "                          learning_rate=0.1,\n",
    "                          depth=6,\n",
    "                          loss_function=CustomDeviationObjective(),\n",
    "                          eval_metric=CustomDeviationMetric(),\n",
    "                          verbose=100)\n",
    "\n",
    "model.fit(X_train_combined, y_train, eval_set=(X_test_combined, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test_combined)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'CatBoost with Russian FastText - Mean Squared Error: {mse}, R-squared: {r2}')\n",
    "def custom_metric(y_true, y_pred):\n",
    "    deviation_1 = ((y_true - y_pred).abs() >= 1).sum() / len(y_true)\n",
    "    deviation_05 = ((y_true - y_pred).abs() >= 0.5).sum() / len(y_true)\n",
    "    \n",
    "    return deviation_1, deviation_05\n",
    "\n",
    "metric_5, metric_20 = custom_metric(y_test, y_pred)\n",
    "print(f'Custom Metric - deviation of 1 or more: {metric_5}, deviation of 0.5 or less: {metric_20}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost with Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import fasttext\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = fasttext.load_model('./cc.ru.300.bin/cc.ru.300.bin')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def get_fasttext_vectors(texts):\n",
    "    return np.array([model.get_word_vector(text) for text in texts])\n",
    "\n",
    "X_train_vacancy_fasttext = get_fasttext_vectors(X_train['Текст вакансии от компании (from Вакансия)'].values)\n",
    "X_train_resume_fasttext = get_fasttext_vectors(X_train['Текст резюме Rollup (from Кандидат)'].values)\n",
    "\n",
    "X_test_vacancy_fasttext = get_fasttext_vectors(X_test['Текст вакансии от компании (from Вакансия)'].values)\n",
    "X_test_resume_fasttext = get_fasttext_vectors(X_test['Текст резюме Rollup (from Кандидат)'].values)\n",
    "\n",
    "X_train_combined = np.hstack((X_train_vacancy_fasttext, X_train_resume_fasttext))\n",
    "X_test_combined = np.hstack((X_test_vacancy_fasttext, X_test_resume_fasttext))\n",
    "\n",
    "model_catboost = CatBoostRegressor(iterations=1000,\n",
    "                                   learning_rate=0.1,\n",
    "                                   depth=6,\n",
    "                                   eval_metric='RMSE',\n",
    "                                   verbose=100)\n",
    "\n",
    "model_catboost.fit(X_train_combined, y_train, eval_set=(X_test_combined, y_test))\n",
    "\n",
    "y_pred = model_catboost.predict(X_test_combined)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'CatBoost with Russian FastText - Mean Squared Error: {mse}, R-squared: {r2}')\n",
    "\n",
    "def custom_metric(y_true, y_pred):\n",
    "    deviation_1 = ((y_true - y_pred).abs() >= 1).sum() / len(y_true)\n",
    "    deviation_05 = ((y_true - y_pred).abs() >= 0.5).sum() / len(y_true)\n",
    "    \n",
    "    return deviation_1, deviation_05\n",
    "\n",
    "metric_5, metric_20 = custom_metric(y_test, y_pred)\n",
    "print(f'Custom Metric - deviation of 1 or more: {metric_5}, deviation of 0.5 or less: {metric_20}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = fasttext.load_model('./cc.ru.300.bin/cc.ru.300.bin')\n",
    "\n",
    "X = df[['Текст вакансии от компании (from Вакансия)', 'Текст резюме Rollup (from Кандидат)']]\n",
    "y = df['Оценка (для проекта)'].apply(convert_score)  # Assuming convert_score is defined\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def get_fasttext_vectors(texts):\n",
    "    return np.array([model.get_word_vector(text) for text in texts])\n",
    "\n",
    "X_train_vacancy_fasttext = get_fasttext_vectors(X_train['Текст вакансии от компании (from Вакансия)'].values)\n",
    "X_train_resume_fasttext = get_fasttext_vectors(X_train['Текст резюме Rollup (from Кандидат)'].values)\n",
    "\n",
    "X_test_vacancy_fasttext = get_fasttext_vectors(X_test['Текст вакансии от компании (from Вакансия)'].values)\n",
    "X_test_resume_fasttext = get_fasttext_vectors(X_test['Текст резюме Rollup (from Кандидат)'].values)\n",
    "\n",
    "X_train_combined = np.hstack((X_train_vacancy_fasttext, X_train_resume_fasttext))\n",
    "X_test_combined = np.hstack((X_test_vacancy_fasttext, X_test_resume_fasttext))\n",
    "\n",
    "model_xgboost = XGBRegressor(n_estimators=1000,\n",
    "                              learning_rate=0.1,\n",
    "                              max_depth=6,\n",
    "                              eval_metric='rmse',\n",
    "                              verbosity=1)\n",
    "\n",
    "model_xgboost.fit(X_train_combined, y_train)\n",
    "\n",
    "y_pred = model_xgboost.predict(X_test_combined)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'XGBoost with Russian FastText - Mean Squared Error: {mse}, R-squared: {r2}')\n",
    "\n",
    "def custom_metric(y_true, y_pred):\n",
    "    deviation_1 = ((y_true - y_pred).abs() >= 1).sum() / len(y_true)\n",
    "    deviation_05 = ((y_true - y_pred).abs() >= 0.5).sum() / len(y_true)\n",
    "    \n",
    "    return deviation_1, deviation_05\n",
    "\n",
    "metric_5, metric_20 = custom_metric(y_test, y_pred)\n",
    "print(f'Custom Metric - deviation of 1 or more: {metric_5}, deviation of 0.5 or less: {metric_20}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "model = fasttext.load_model('./cc.ru.300.bin/cc.ru.300.bin')\n",
    "\n",
    "X = df[['Текст вакансии от компании (from Вакансия)', 'Текст резюме Rollup (from Кандидат)']]\n",
    "y = df['Оценка (для проекта)'].apply(convert_score)  # Assuming convert_score is defined\n",
    "\n",
    "X['Текст вакансии от компании (from Вакансия)'] = X['Текст вакансии от компании (from Вакансия)'].apply(preprocess_text)\n",
    "X['Текст резюме Rollup (from Кандидат)'] = X['Текст резюме Rollup (from Кандидат)'].apply(preprocess_text)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def get_fasttext_vectors(texts):\n",
    "    return np.array([model.get_word_vector(text) for text in texts])\n",
    "\n",
    "X_train_vacancy_fasttext = get_fasttext_vectors(X_train['Текст вакансии от компании (from Вакансия)'].values)\n",
    "X_train_resume_fasttext = get_fasttext_vectors(X_train['Текст резюме Rollup (from Кандидат)'].values)\n",
    "\n",
    "X_test_vacancy_fasttext = get_fasttext_vectors(X_test['Текст вакансии от компании (from Вакансия)'].values)\n",
    "X_test_resume_fasttext = get_fasttext_vectors(X_test['Текст резюме Rollup (from Кандидат)'].values)\n",
    "\n",
    "X_train_combined = np.hstack((X_train_vacancy_fasttext, X_train_resume_fasttext))\n",
    "X_test_combined = np.hstack((X_test_vacancy_fasttext, X_test_resume_fasttext))\n",
    "\n",
    "base_models = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    ('xgb', XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)),\n",
    "    ('catboost', CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, verbose=0))\n",
    "]\n",
    "\n",
    "stacked_model = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
    ")\n",
    "\n",
    "stacked_model.fit(X_train_combined, y_train)\n",
    "\n",
    "y_pred_stacked = stacked_model.predict(X_test_combined)\n",
    "\n",
    "mse_final = mean_squared_error(y_test, y_pred_stacked)\n",
    "r2_final = r2_score(y_test, y_pred_stacked)\n",
    "print(f'Stacked Model - Mean Squared Error: {mse_final}, R-squared: {r2_final}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
